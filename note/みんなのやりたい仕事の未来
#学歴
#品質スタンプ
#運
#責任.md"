---
title: みんなのやりたい仕事の未来 #学歴 #品質スタンプ #運 #責任｜konaito
description: 0．はじめに  私は，エンジニア，起業家をしている23歳です．もともと大学で数学を勉強していたのですが，学部2年生の冬にChatGPTがローンチされ，そこまでやってきたプログラミングの勉強が”無駄になる”，”陳腐化してしまう”と思い，休学し，東京に上京，最初の一年はハッカソンに多く出場する年とし自分のエンジニアとしての位置を見極め，二年目に起業しました．詳しくは．別ノートで書いております．  自分自身が，このような境遇のためAIの社会進出，社会浸透に人一倍気にかけております．その中でエンジニア向けに書かれた（非エンジニアの人もぜひ読むことでAIがどれくらい業務進行プロセスに対して浸透し
url: https://note.com/konaito/n/nce6c033404fb
image: https://assets.st-note.com/production/uploads/images/186351532/rectangle_large_type_2_fec84e119e52ac957e11921e454728fc.png?fit=bounds&quality=85&width=1280
siteName: note（ノート）
type: article
twitterCard: undefined
twitterSite: undefined
---
# みんなのやりたい仕事の未来：学歴、品質スタンプ、運、責任

23歳でエンジニア兼起業家として活動する筆者が、AIの急速な社会浸透に伴う「賢さ」の価値の変化と、これからの時代を生き抜くための在り方について考察します。

## 0. はじめに

大学で数学を専攻していた筆者は、 2年次にAIの登場を機にプログラミングの学習が「無駄になる」と感じ、休学。ハッカソンへの参加を経てエンジニアとしての自身の立ち位置を探り、起業に至りました。この経験から、AIの社会進出に強い関心を持っています。

本稿は、AIコーディングツールの進化とエンジニアの仕事への影響を記した「エンジニアに許された特別な時間の終わり」というスライドを一般化し、AIが代替していく過程に焦点を当てて論じています。

## 1. 賢さは優位性だった時代からの転換

### 「賢さ」が通貨だった時代からの転換点

生成AIがコードや契約書、ニュース記事などを瞬時に生成する現在、**「頭が良い＝価値が高い」**という図式は過去のものとなりつつあります。かつて、東京大学やアイビーリーグといった学位は、その人物に任せれば間違いないという「知の通貨」として機能し、高い報酬や裁量を約束していました。

しかし、AIが人間と同等以上の成果を出すようになったことで、学歴という「ラベル」は、経営者が「責任転嫁」のために用いる**〈品質スタンプ〉**としての意味合いを強めています。これは、労働市場と社会構造が恒久的に再編成される兆しです。

本稿では、この変化を「運」と「責任」というキーワードで捉え、**今後3〜7年で起こりうる利益モデルの変化**と、「仕事がなくなるかもしれない未来」を生き抜くための視点を提供します。単なるスキルアップではなく、より構造的な視点から個人の生存戦略を考察し、読者が自らの頭で「設計図を書く」ためのきっかけとなることを目指します。

## 2. 利益モデルの変遷

### 2-1. 企業の計算式：三段階の変化

企業は常に合理的な意思決定を追求します。AIによるアウトプットの価値が向上するにつれて、企業が人材に支払う対価の性質は以下のように変化します。

*   **稼働（実務費）:** 労働時間、工数、専門スキルに対する直接的な対価。
*   **保険料（信用費、免責費）:** AIのアウトプットに「人間の保証印」を押し、万が一の際に責任を負うための対価。

企業は、ROI（投資対効果）がプラスである限り、高学歴という「品質スタンプ」にコストを払い続けます。しかし、その支払いの本質は、実務から信用、そして最終的には責任の免除へと質的に変容していきます。この流れは業界差こそあれ、不可逆的なトレンドです。

### 2-2. スタンプ雇用が「免責ラベル」化する理由

この変化は、組織心理と法的リスク管理から必然的に生じます。

1.  **採用の正当性:** 「有名大学出身者なら安心」という説明は、ステークホルダーに対する説得力があり、採用の正当性を示しやすい。
2.  **失敗時の逃げ道:** 優秀な人材でも失敗したという状況は、「仕方なかった」という文脈を生み出し、責任の所在を曖昧にする効果がある。
3.  **AIへの全信任への不安:** 最終的な判断をAIに委ねることへの心理的障壁は依然として存在し、学歴を持つ人間が「安全キャップ」の役割を担う。

この「スタンプ雇用」は、AIと人間の役割分担における構造的な均衡点として定着する可能性があります。

## 3. 「運と責任」が残る仕組み：「AIマインスイーパー」のメタファー

AIの進化が労働環境に与える影響を理解するために、「AIマインスイーパー」というメタファーを提案します。

*   **AIの役割:** 論理的に解けるマスをすべて開ける。
*   **人間の役割:** ランダムなマスをクリックする。
*   **結果:** 地雷を踏めばゲームオーバー＝人間が最終的な責任を負う。

従来のマインスイーパーは、プレイヤーが論理的推論とリスク判断の両方を担っていました。しかし「AIマインスイーパー」では、AIが論理的推論を肩代わりし、人間には「運任せのクリック」だけが残されます。これは、AIが「パターン認識」「大量データ処理」「論理的演繹」といった領域を担い、人間には「最終判断」「対人説明」「責任負担」といった領域が濃縮されていく、これからの労働市場における人間の役割を象徴しています。

これは単なる業務効率化ではなく、「人間の仕事の本質的な再定義」を意味し、責任の重さと引き換えに実務作業から解放されるというトレードオフが進行しています。

## 4. 国際政治が加速するAI導入

### 「トランプ2.0」という外部ショック

2025年のアメリカ大統領選挙でトランプ氏が再登板し、「AI利用を国家成長の最優先課題とする」と明言した場合、技術導入のタイムラインは劇的に加速する可能性があります。国防、医療、金融分野を中心に**ラディカルな規制緩和と国家投資**が行われ、世界のルールが急速に書き換わるでしょう。

アメリカ主導の「AIファースト」政策は、国際競争力と地政学的な優位性を確保するための戦略であり、AIの社会実装は「理想的な速度」ではなく「経済的・政治的に必要な速度」で進む inevitability があります。

この外圧に対し、日本企業は**2～3年以内に追随か対抗かの意思決定**を迫られます。制度整備を待つ余裕はなく、**個人も企業も「自己設計」を先延ばしできない**状況です。能動的に自らの立ち位置を定義し直す必要があります。

## 5. 「仕事がなくなる」前提で逆算する

### タイムラインで見る「労働消失」の可能性

AIは当初、人間の生産性を補完する「道具」として機能しますが、徐々に多くのタスクを代替していきます。最終的には、従来型の労働市場が構造的に縮小し、「所得獲得の手段としての仕事」という概念自体が再定義される可能性があります。

労働需要の恒常的な不足は、ユニバーサルベーシックインカム（UBI）のような社会保障制度の導入も視野に入れる必要性を示唆しています。これは、社会安定化のための経済政策という側面も持ちます。

## 6. 結び

### 6-1. 「働く」ことが前提でなくなる世界で、まず考えるべきこと

私たちは、**ベーシックインカム（BI）さえ現実的な選択肢として検討せざるを得ないほどラディカルな時代**に生きています。AIが「作業」も「判断」も肩代わりし、国際政治はAIの拡張を国家戦略として競い合う中で、**仕事そのものが社会から消える可能性**が「もし」ではなく「いつ」の問題となりつつあります。

### 6-2. 「収入＝労働の対価」という常識をいったん棚上げする

*   終身雇用が崩れ、副業推奨が当たり前になったのは序章にすぎません。
*   AIが安価かつ高速になった時、**「労働」そのものがコスト高**になる産業が増加します。
*   国家は社会を回すための最低限の購買力を維持するため、**BIなどの非労働所得モデル**を制度として検討せざるを得なくなります。

### 6-3. 「思考停止の委託先」はどこにもない

「AIを使いこなせるか」という競争は、まもなく終わります。**制度が追いつかなければ、生活の土台そのものが揺らぐ**可能性があります。**ラディカルな時代を生き抜くための最初の条件は、他人や制度の決定を待たずに、自らの未来を「自分の頭」で主体的に設計し始めること**です。

> ベーシックインカムが来ても来なくても、
> 仕事があってもなくても、
> **確率分布的に自身の人生に対する責任という布石を打つ必要があります。**

## 7. 仕事が残る、と考えられる世界線

ここでは、AIがすべてを代替するわけではない、仕事が残る可能性のある世界線について考察します。

### 7-1. LLM（大規模言語モデル）の限界

LLM（大規模言語モデル）は、Transformerアーキテクチャを基盤とした確率モデルであり、ChatGPTなどもこのモデルで成り立っています。しかし、「スケール則（scale law）」によると、AIは万能になるというよりは、**費用対効果が先に頭打ちになる**可能性が示唆されています。

また、AIには物理的な制約も存在します。クラウドAIの主な原料である電気、GPU、冷却水、土地、送電網といった資源は有限であり、「電源コードを挿せば無限に計算できる」という状況は幻想です。資源制約により、AIの供給が社会の需要に追いつかない可能性も考えられます。

### 7-2. 人間がAIに託しきれない領域

AIは「確率的に最適」な回答を生成するかもしれませんが、「絶対に正しい」とは限りません。

*   **説明責任:** 裁判、医療、公共政策など、責任の所在が問われる分野では、AIのブラックボックスな推論根拠だけでは社会的な合意形成が困難です。
*   **文化・情緒・身体性:** 介護、教育、接遇のように、相手の気配を読み、微妙な間合いを理解するような行為は、定量化しにくい暗黙知に支えられています。
*   **価値観の揺らぎ:** 生成AIの出力は、学習データのバイアスを継承します。「正義」や「公正」といった価値観は社会ごとに異なるため、最終的な判断は人間が担わざるを得ません。

総じて、AIは「論理の重労働者」にはなれても、「異議申し立てを受け止める人格」にはまだなれないのが現状です。

### 7-3. 経営者が「寂しさ」から雇用を続ける可能性

筆者の起業経験から、経営者との対話で興味深い見解がありました。AIが効率を追求するほど、逆に「人的コストを払ってでも保ちたい人間関係」が重要になるというものです。家族や友人とは異なる、**「寂しさを埋めるツールとしての社員」**の役割が、AI時代に再定義される可能性が示唆されています。